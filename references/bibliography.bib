@article{Frankema2020,
   author = {Ewout Frankema and Heidi Tworek},
   doi = {10.1017/S1740022820000339},
   issn = {17400236},
   issue = {3},
   journal = {Journal of Global History},
   month = {11},
   pages = {333-335},
   publisher = {Cambridge University Press},
   title = {Pandemics that changed the world: Historical reflections on COVID-19},
   volume = {15},
   year = {2020},
}
@misc{,
   abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
   author = {Fabian Pedregosa FABIANPEDREGOSA and Vincent Michel and Olivier Grisel OLIVIERGRISEL and Mathieu Blondel and Peter Prettenhofer and Ron Weiss and Jake Vanderplas and David Cournapeau and Fabian Pedregosa and Gaël Varoquaux and Alexandre Gramfort and Bertrand Thirion and Olivier Grisel and Vincent Dubourg and Alexandre Passos and Matthieu Brucher and Matthieu Perrot andÉdouardand and andÉdouard Duchesnay and FRÉdouard Duchesnay EDOUARDDUCHESNAY},
   journal = {Journal of Machine Learning Research},
   keywords = {Python,model selection,supervised learning,unsupervised learning},
   pages = {2825-2830},
   title = {Scikit-learn: Machine Learning in Python Gaël Varoquaux Bertrand Thirion Vincent Dubourg Alexandre Passos PEDREGOSA, VAROQUAUX, GRAMFORT ET AL. Matthieu Perrot},
   volume = {12},
   url = {http://scikit-learn.sourceforge.net.},
   year = {2011},
}
@misc{,
   abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
   author = {Ashish Vaswani and Google Brain and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N Gomez and Łukasz Kaiser and Illia Polosukhin},
   title = {Attention Is All You Need},
}
@misc{Rigatti2017,
   abstract = {For the task of analyzing survival data to derive risk factors associated with mortality, physicians, researchers, and biostatisticians have typically relied on certain types of regression techniques, most notably the Cox model. With the advent of more widely distributed computing power, methods which require more complex mathematics have become increasingly common. Particularly in this era of "big data" and machine learning, survival analysis has become method-ologically broader. This paper aims to explore one technique known as Random Forest. The Random Forest technique is a regression tree technique which uses bootstrap aggregation and randomization of predictors to achieve a high degree of predictive accuracy. The various input parameters of the random forest are explored. Colon cancer data (n = 66,807) from the SEER database is then used to construct both a Cox model and a random forest model to determine how well the models perform on the same data. Both models perform well, achieving a concordance error rate of approximately 18%.},
   author = {Steven J Rigatti},
   journal = {JOURNAL OF INSURANCE MEDICINE Copyright C 2017 Journal of Insurance Medicine J Insur Med},
   pages = {31-39},
   title = {Random Forest},
   volume = {47},
   url = {http://meridian.allenpress.com/jim/article-pdf/47/1/31/1736157/insm-47-01-31-39_1.pdf},
   year = {2017},
}
@misc{,
   title = {Comparing Random Forest, XGBoost and Neural Networks With Hyperparameter Optimization by Nested Cross-Validation},
}
@book{,
   author = {Institute of Electrical and Electronics Engineers},
   isbn = {9781424418213},
   title = {Neural Networks, 2008, IJCNN 2008, (IEEE World Congress on Computational Intelligence), IEEE International Joint Conference on : date, 1-8 June 2008.},
}
@book{,
   author = {Institute of Electrical and Electronics Engineers},
   isbn = {9781424418213},
   title = {Neural Networks, 2008, IJCNN 2008, (IEEE World Congress on Computational Intelligence), IEEE International Joint Conference on : date, 1-8 June 2008.},
}
@misc{,
   abstract = {In this paper we will discuss pandas, a Python library of rich data structures and tools for working with structured data sets common to statistics, finance, social sciences, and many other fields. The library provides integrated, intuitive routines for performing common data manipulations and analysis on such data sets. It aims to be the foundational layer for the future of statistical computing in Python. It serves as a strong complement to the existing scientific Python stack while implementing and improving upon the kinds of data manipulation tools found in other statistical programming languages such as R. In addition to detailing its design and features of pandas, we will discuss future avenues of work and growth opportunities for statistics and data analysis applications in the Python language.},
   author = {Wes Mckinney},
   title = {pandas: a Foundational Python Library for Data Analysis and Statistics},
   url = {http://pandas.sf.net},
}
@article{Wolf2019,
   abstract = {Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. \textit\{Transformers\} is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. \textit\{Transformers\} is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at \url\{https://github.com/huggingface/transformers\}.},
   author = {Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush},
   month = {10},
   title = {HuggingFace's Transformers: State-of-the-art Natural Language Processing},
   url = {http://arxiv.org/abs/1910.03771},
   year = {2019},
}
@book{,
   abstract = {"IEEE Catalog Number: CFP18BIB-ART"--PDF copyright page},
   author = {Huiru Zheng and Ulster University and Universidad de Granada and Universidad Carlos III de Madrid and Institute of Electrical and Electronics Engineers and IEEE Computer Society and IEEE Computer Society. Technical Committee on Computational Life Sciences},
   isbn = {9781538654880},
   title = {Proceedings, 2018 IEEE International Conference on Bioinformatics and Biomedicine : 3-6 Dec. 2018, Madrid, Spain},
}
@misc{Harris2020,
   abstract = {Array programming provides a powerful, compact and expressive syntax for accessing, manipulating and operating on data in vectors, matrices and higher-dimensional arrays. NumPy is the primary array programming library for the Python language. It has an essential role in research analysis pipelines in fields as diverse as physics, chemistry, astronomy, geoscience, biology, psychology, materials science, engineering, finance and economics. For example, in astronomy, NumPy was an important part of the software stack used in the discovery of gravitational waves1 and in the first imaging of a black hole2. Here we review how a few fundamental array concepts lead to a simple and powerful programming paradigm for organizing, exploring and analysing scientific data. NumPy is the foundation upon which the scientific Python ecosystem is constructed. It is so pervasive that several projects, targeting audiences with specialized needs, have developed their own NumPy-like interfaces and array objects. Owing to its central position in the ecosystem, NumPy increasingly acts as an interoperability layer between such array computation libraries and, together with its application programming interface (API), provides a flexible framework to support the next decade of scientific and industrial analysis.},
   author = {Charles R. Harris and K. Jarrod Millman and Stéfan J. van der Walt and Ralf Gommers and Pauli Virtanen and David Cournapeau and Eric Wieser and Julian Taylor and Sebastian Berg and Nathaniel J. Smith and Robert Kern and Matti Picus and Stephan Hoyer and Marten H. van Kerkwijk and Matthew Brett and Allan Haldane and Jaime Fernández del Río and Mark Wiebe and Pearu Peterson and Pierre Gérard-Marchant and Kevin Sheppard and Tyler Reddy and Warren Weckesser and Hameer Abbasi and Christoph Gohlke and Travis E. Oliphant},
   doi = {10.1038/s41586-020-2649-2},
   issn = {14764687},
   issue = {7825},
   journal = {Nature},
   month = {9},
   pages = {357-362},
   pmid = {32939066},
   publisher = {Nature Research},
   title = {Array programming with NumPy},
   volume = {585},
   year = {2020},
}
@misc{Breiman2001,
   abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, * * * , 148-156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
   author = {Leo Breiman},
   keywords = {classification,ensemble,regression},
   pages = {5-32},
   title = {Random Forests},
   volume = {45},
   year = {2001},
}
@misc{Gest2004,
   abstract = {The existence of microscopic organisms was discovered during the period 1665-83 by two Fellows of The Royal Society, Robert Hooke and Antoni van Leeuwenhoek. In Micrographia (1665), Hooke presented the first published depiction of a microrganism, the microfungus Mucor. Later, Leeuwenhoek observed and described microscopic protozoa and bacteria. These important revelations were made possible by the ingenuity of Hooke and Leeuwenhoek in fabricating and using simple microscopes that magnified objects from about 25-fold to 250-fold. After a lapse of more than 150 years, microscopy became the backbone of our understanding of the roles of microbes in the causation of infectious diseases and the recycling of chemical elements in the biosphere.},
   author = {Howard Gest},
   doi = {10.1098/rsnr.2004.0055},
   issn = {17430178},
   issue = {2},
   journal = {Notes and Records of the Royal Society},
   keywords = {Antoni van Leeuwenhoek,Fellows of The Royal Society,Micrographia,Microscope,Robert Hooke},
   pages = {187-201},
   pmid = {15209075},
   publisher = {Royal Society},
   title = {The discovery of microorganisms by Robert Hooke and Antoni van Leeuwenhoek, fellows of the Royal Society},
   volume = {58},
   year = {2004},
}
@article{Raffel2019,
   abstract = {Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new ``Colossal Clean Crawled Corpus'', we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our data set, pre-trained models, and code.},
   author = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
   month = {10},
   title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
   url = {http://arxiv.org/abs/1910.10683},
   year = {2019},
}
@article{Parvandeh2020,
   abstract = {Feature selection can improve the accuracy of machine-learning models, but appropriate steps must be taken to avoid overfitting. Nested cross-validation (nCV) is a common approach that chooses the classification model and features to represent a given outer fold based on features that give the maximum inner-fold accuracy. Differential privacy is a related technique to avoid overfitting that uses a privacy-preserving noise mechanism to identify features that are stable between training and holdout sets. We develop consensus nested cross-validation (cnCV) that combines the idea of feature stability from differential privacy with nCV. Feature selection is applied in each inner fold and the consensus of top features across folds is used as a measure of feature stability or reliability instead of classification accuracy, which is used in standard nCV. We use simulated data with main effects, correlation and interactions to compare the classification accuracy and feature selection performance of the new cnCV with standard nCV, Elastic Net optimized by cross-validation, differential privacy and private evaporative cooling (pEC). We also compare these methods using real RNA-seq data from a study of major depressive disorder. The cnCV method has similar training and validation accuracy to nCV, but cnCV has much shorter run times because it does not construct classifiers in the inner folds. The cnCV method chooses a more parsimonious set of features with fewer false positives than nCV. The cnCV method has similar accuracy to pEC and cnCV selects stable features between folds without the need to specify a privacy threshold. We show that cnCV is an effective and efficient approach for combining feature selection with classification.},
   author = {Saeid Parvandeh and Hung Wen Yeh and Martin P. Paulus and Brett A. McKinney},
   doi = {10.1093/bioinformatics/btaa046},
   issn = {14602059},
   issue = {10},
   journal = {Bioinformatics},
   month = {5},
   pages = {3093-3098},
   pmid = {31985777},
   publisher = {Oxford University Press},
   title = {Consensus features nested cross-validation},
   volume = {36},
   year = {2020},
}
@misc{,
   abstract = {imbalanced-learn is an open-source python toolbox aiming at providing a wide range of methods to cope with the problem of imbalanced dataset frequently encountered in machine learning and pattern recognition. The implemented state-of-the-art methods can be categorized into 4 groups: (i) under-sampling, (ii) over-sampling, (iii) combination of over-and under-sampling, and (iv) ensemble learning methods. The proposed toolbox depends only on numpy, scipy, and scikit-learn and is distributed under MIT license. Furthermore , it is fully compatible with scikit-learn and is part of the scikit-learn-contrib supported project. Documentation, unit tests as well as integration tests are provided to ease usage and contribution. Source code, binaries, and documentation can be downloaded from https://github.com/scikit-learn-contrib/imbalanced-learn.},
   author = {Guillaume LemaˆıtreLemaˆıtre and Fernando Nogueira and Christos K Aridas char},
   journal = {Journal of Machine Learning Research},
   keywords = {Ensemble Learning,Imbalanced Dataset,Machine Learning,Over-Sampling,Python,Under-Sampling},
   pages = {1-5},
   title = {Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning},
   volume = {18},
   url = {http://jmlr.org/papers/v18/16-365.html.},
   year = {2017},
}
@article{Biau2016,
   abstract = {The random forest algorithm, proposed by L. Breiman in 2001, has been extremely successful as a general-purpose classification and regression method. The approach, which combines several randomized decision trees and aggregates their predictions by averaging, has shown excellent performance in settings where the number of variables is much larger than the number of observations. Moreover, it is versatile enough to be applied to large-scale problems, is easily adapted to various ad hoc learning tasks, and returns measures of variable importance. The present article reviews the most recent theoretical and methodological developments for random forests. Emphasis is placed on the mathematical forces driving the algorithm, with special attention given to the selection of parameters, the resampling mechanism, and variable importance measures. This review is intended to provide non-experts easy access to the main ideas.},
   author = {Gérard Biau and Erwan Scornet},
   doi = {10.1007/s11749-016-0481-7},
   issn = {11330686},
   issue = {2},
   journal = {Test},
   keywords = {Parameter tuning,Random forests,Randomization,Resampling,Variable importance},
   month = {6},
   pages = {197-227},
   publisher = {Springer New York LLC},
   title = {A random forest guided tour},
   volume = {25},
   year = {2016},
}
@misc{Frieri2017,
   abstract = {Antimicrobial resistance in bacterial pathogens is a challenge that is associated with high morbidity and mortality. Multidrug resistance patterns in Gram-positive and -negative bacteria are difficult to treat and may even be untreatable with conventional antibiotics. There is currently a shortage of effective therapies, lack of successful prevention measures, and only a few new antibiotics, which require development of novel treatment options and alternative antimicrobial therapies. Biofilms are involved in multidrug resistance and can present challenges for infection control. Virulence, Staphylococcus aureus, Clostridium difficile infection, vancomycin-resistant enterococci, and control in the Emergency Department are also discussed.},
   author = {Marianne Frieri and Krishan Kumar and Anthony Boutin},
   doi = {10.1016/j.jiph.2016.08.007},
   issn = {1876035X},
   issue = {4},
   journal = {Journal of Infection and Public Health},
   keywords = {Antibiotic resistance,Biofilms,Emergency Department,Infections,Public health},
   month = {7},
   pages = {369-378},
   pmid = {27616769},
   publisher = {Elsevier Ltd},
   title = {Antibiotic resistance},
   volume = {10},
   year = {2017},
}
@book{,
   abstract = {"IEEE Catalog Number: CFP18BIB-ART"--PDF copyright page},
   author = {Huiru Zheng and Ulster University and Universidad de Granada and Universidad Carlos III de Madrid and Institute of Electrical and Electronics Engineers and IEEE Computer Society and IEEE Computer Society. Technical Committee on Computational Life Sciences},
   isbn = {9781538654880},
   title = {Proceedings, 2018 IEEE International Conference on Bioinformatics and Biomedicine : 3-6 Dec. 2018, Madrid, Spain},
}
@article{,
   title = {Elnaggar_supplemental},
}
@article{Gonzales2023,
   abstract = {With the growing interest in using phages to combat antimicrobial resistance, computational methods for predicting phage-host interactions have been explored to help shortlist candidate phages. Most existing models consider entire proteomes and rely on manual feature engineering, which poses difficulty in selecting the most informative sequence properties to serve as input to the model. In this paper, we framed phage-host interaction prediction as a multiclass classification problem that takes as input the embeddings of a phage’s receptor-binding proteins, which are known to be the key machinery for host recognition, and predicts the host genus. We explored different protein language models to automatically encode these protein sequences into dense embeddings without the need for additional alignment or structural information. We show that the use of embeddings of receptor-binding proteins presents improvements over handcrafted genomic and protein sequence features. The highest performance was obtained using the transformer-based protein language model ProtT5, resulting in a 3% to 4% increase in weighted F1 and recall scores across different prediction confidence thresholds, compared to using selected handcrafted sequence features.},
   author = {Mark Edward M. Gonzales and Jennifer C. Ureta and Anish M.S. Shrestha},
   doi = {10.1371/journal.pone.0289030},
   issn = {19326203},
   issue = {7 JULY},
   journal = {PLoS ONE},
   month = {7},
   pmid = {37486915},
   publisher = {Public Library of Science},
   title = {Protein embeddings improve phage-host interaction prediction},
   volume = {18},
   year = {2023},
}
@article{Elnaggar2022,
   abstract = {Computational biology and bioinformatics provide vast data gold-mines from protein sequences, ideal for Language Models (LMs) taken from Natural Language Processing (NLP). These LMs reach for new prediction frontiers at low inference costs. Here, we trained two auto-regressive models (Transformer-XL, XLNet) and four auto-encoder models (BERT, Albert, Electra, T5) on data from UniRef and BFD containing up to 393 billion amino acids. The protein LMs (pLMs) were trained on the Summit supercomputer using 5616 GPUs and TPU Pod up-to 1024 cores. Dimensionality reduction revealed that the raw pLM-embeddings from unlabeled data captured some biophysical features of protein sequences. We validated the advantage of using the embeddings as exclusive input for several subsequent tasks: (1) a per-residue (per-token) prediction of protein secondary structure (3-state accuracy Q3=81%-87%); (2) per-protein (pooling) predictions of protein sub-cellular location (ten-state accuracy: Q10=81%) and membrane versus water-soluble (2-state accuracy Q2=91%). For secondary structure, the most informative embeddings (ProtT5) for the first time outperformed the state-of-the-art without multiple sequence alignments (MSAs) or evolutionary information thereby bypassing expensive database searches. Taken together, the results implied that pLMs learned some of the grammar of the language of life. All our models are available through https://github.com/agemagician/ProtTrans.},
   author = {Ahmed Elnaggar and Michael Heinzinger and Christian Dallago and Ghalia Rehawi and Yu Wang and Llion Jones and Tom Gibbs and Tamas Feher and Christoph Angerer and Martin Steinegger and Debsindhu Bhowmik and Burkhard Rost},
   doi = {10.1109/TPAMI.2021.3095381},
   issn = {19393539},
   issue = {10},
   journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
   keywords = {Computational biology,deep learning,high performance computing,language modeling,machine learning},
   month = {10},
   pages = {7112-7127},
   pmid = {34232869},
   publisher = {IEEE Computer Society},
   title = {ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning},
   volume = {44},
   year = {2022},
}
@article{Yuan2021,
   abstract = {In the past few decades, DPA-based side-channel attack strategies, such as DPA and CPA, have shown strong ability to analyze the security of the cryptographic implementations. However, the unpredictability of the leakage model and the correspondence between leakage behavior of the target device and the hypothetical leakage value make it less-effective without prior knowledge. Therefore, in this paper, we present a novel generic side-channel analysis method called Gini-impurity Index Analysis (GIA), utilizing Gini-impurity Index as the distinguisher, which can perform well even without any leakage model and is not sensitive to the existing methods' restrictions about the leakage behavior. Firstly, we introduce the basic idea of GIA. According to the proposed GIA attack strategy, the Gini-impurity index for each key hypothesis should be calculated, determined by the clustered power consumption and the classified subsets based on the key dependent target function. Secondly, we verify the feasibility and evaluate the efficiency of GIA with different target functions by the practical experimental results against AES-128 implemented on an AT89S52 microcontroller. We present one possible multivariate extension of GIA and find the advantage of GIA on leakage information utilization. Thirdly, we present the results of comparisons. On the one hand, we compare GIA with three widely-used distinguishers under simulated traces in various leakage scenarios and practical traces with Hamming-weight-related leakage. Results confirm that GIA can always perform well with different leakage models in most situations. On the other hand, we analyze the relationship between GIA and Mutual Information Analysis (MIA). Theoretical and experimental results confirm that these two methods can obtain similar attack results. However, the guessing entropy of GIA is lower than MIA by up to 21%, and the averaged computational time overhead of GIA is lower than MIA by up to 13.3%, indicating that GIA is more efficient than MIA. Compared to traditional MIA, GIA is easier to operate and more flexible with noise. Therefore, GIA is an efficient and useful alternative to these existed strategies.},
   author = {Ye Yuan and Liji Wu and Xiangmin Zhang},
   doi = {10.1109/TIFS.2021.3076932},
   issn = {15566021},
   journal = {IEEE Transactions on Information Forensics and Security},
   keywords = {Gini-impurity index,differential power analysis,performance evaluation,side-channel attack},
   pages = {3154-3169},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Gini-Impurity Index Analysis},
   volume = {16},
   year = {2021},
}
@misc{Chawla2002,
   abstract = {An approach to the construction of classifiers from imbalanced datasets is described. A dataset is imbalanced if the classification categories are not approximately equally represented. Often real-world data sets are predominately composed of "normal" examples with only a small percentage of "abnormal" or "interesting" examples. It is also the case that the cost of misclassifying an abnormal (interesting) example as a normal example is often much higher than the cost of the reverse error. Under-sampling of the majority (nor-mal) class has been proposed as a good means of increasing the sensitivity of a classifier to the minority class. This paper shows that a combination of our method of over-sampling the minority (abnormal) class and under-sampling the majority (normal) class can achieve better classifier performance (in ROC space) than only under-sampling the majority class. This paper also shows that a combination of our method of over-sampling the minority class and under-sampling the majority class can achieve better classifier performance (in ROC space) than varying the loss ratios in Ripper or class priors in Naive Bayes. Our method of over-sampling the minority class involves creating synthetic minority class examples. Experiments are performed using C4.5, Ripper and a Naive Bayes classifier. The method is evaluated using the area under the Receiver Operating Characteristic curve (AUC) and the ROC convex hull strategy.},
   author = {Nitesh V Chawla and Kevin W Bowyer and Lawrence O Hall and W Philip Kegelmeyer},
   journal = {Journal of Artificial Intelligence Research},
   pages = {321-357},
   title = {SMOTE: Synthetic Minority Over-sampling Technique},
   volume = {16},
   year = {2002},
}
@book{Ketkar2021,
   abstract = {Master the practical aspects of implementing deep learning solutions with PyTorch, using a hands-on approach to understanding both theory and practice. This updated edition will prepare you for applying deep learning to real world problems with a sound theoretical foundation and practical know-how with PyTorch, a platform developed by Facebook's Artificial Intelligence Research Group. You'll start with a perspective on how and why deep learning with PyTorch has emerged as an path-breaking framework with a set of tools and techniques to solve real-world problems. Next, the book will ground you with the mathematical fundamentals of linear algebra, vector calculus, probability and optimization. Having established this foundation, you'll move on to key components and functionality of PyTorch including layers, loss functions and optimization algorithms. You'll also gain an understanding of Graphical Processing Unit (GPU) based computation, which is essential for training deep learning models. All the key architectures in deep learning are covered, including feedforward networks, convolution neural networks, recurrent neural networks, long short-term memory networks, autoencoders and generative adversarial networks. Backed by a number of tricks of the trade for training and optimizing deep learning models, this edition of Deep Learning with Python explains the best practices in taking these models to production with PyTorch.},
   author = {Nikhil Ketkar and Jojo Moolayil},
   doi = {10.1007/978-1-4842-5364-9},
   isbn = {9781484253649},
   journal = {Deep Learning with Python: Learn Best Practices of Deep Learning Models with PyTorch},
   keywords = {Advanced PyTorch,Deep Learning,Deep Networks,Machine Learning,PyTorch,Python},
   month = {4},
   pages = {1-306},
   publisher = {Apress Media LLC},
   title = {Deep learning with python: Learn Best Practices of Deep Learning Models with PyTorch},
   year = {2021},
}
@inbook{Imambi2021,
   abstract = {PyTorch is a library for Python programs that encourages deep learning programs. With this receptiveness and convenience found in (Deep Learning for Computer Vision: Expert techniques to train advanced neural networks using TensorFlow and Keras. [Authors: RajalingappaaShanmugamani]), PyTorch makes it useful in developing deep neural networks. It has an expansive scope and is applied for various applications. As Python is for programming, PyTorch is both a magnificent prologue to profound learning just as an instrument usable in proficient real-world applications.},
   author = {Sagar Imambi and Kolla Bhanu Prakash and G. R. Kanagachidambaresan},
   doi = {10.1007/978-3-030-57077-4_10},
   issn = {25228609},
   journal = {EAI/Springer Innovations in Communication and Computing},
   keywords = {Deep learning,PyTorch,Python},
   pages = {87-104},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {PyTorch},
   year = {2021},
}
@misc{,
   abstract = {T he backbone of scientific computing is mostly a collection of high-performance code written in Fortran, C, and C++ that typically runs in batch mode on large systems, clusters, and supercomputers. However, over the past decade, high-level environments that integrate easy-to-use interpreted languages , comprehensive numerical libraries, and visualization facilities have become extremely popular in this field. As hardware becomes faster, the critical bottleneck in scientific computing isn't always the computer's processing time; the scientist's time is also a consideration. For this reason, systems that allow rapid algorithmic exploration, data analysis, and vi-sualization have become a staple of daily scientific work. The Interactive Data Language (IDL) and Matlab (for numerical work), and Mathematica and Maple (for work that includes symbolic manipulation) are well-known commercial environments of this kind. GNU Data Language, Octave, Maxima and Sage provide their open source counterparts. All these systems offer an interactive command line in which code can be run immediately, without having to go through the traditional edit/ compile/execute cycle. This flexible style matches well the spirit of computing in a scientific context, in which determining what computations must be performed next often requires significant work. An interactive environment lets scientists look at data, test new ideas, combine algorithmic approaches , and evaluate their outcomes directly. This process might lead to a final result, or it might clarify how to build a more static, large-scale production code. As this article shows, Python (www.python.org) is an excellent tool for such a workflow. 1 The IPython project (http://ipython.scipy.org) aims to not only provide a greatly enhanced Python shell but also facilities for interactive distributed and parallel computing, as well as a comprehensive set of tools for building special-purpose interactive environments for scientific computing. Python: An Open and General-Purpose Environment The fragment in Figure 1 shows the default interactive Python shell, including a computation with long integers (whose size is limited only by the available memory) and one using the built-in complex numbers, where the literal 1j represents. i 1 Python offers basic facilities for interactive work and a comprehensive library on top of which more sophisticated systems can be built. The IPython project provides an enhanced interactive environment that includes, among other features, support for data visualization and facilities for distributed and parallel computation.},
   author = {Fernando Pérez and Brian E Granger},
   title = {IPython: A System for Interactive Scientific Computing},
   url = {www.python.org},
}
@article{Furniss2022,
   abstract = {Antimicrobial resistance in Gram-negative bacteria is one of the greatest threats to global health. New antibacterial strategies are urgently needed, and the development of antibiotic adjuvants that either neutralize resistance proteins or compromise the integrity of the cell envelope is of ever-growing interest. Most available adjuvants are only effective against specific resistance proteins. Here we demonstrate that disruption of cell envelope protein homeostasis simultaneously compromises several classes of resistance determinants. In particular, we find that impairing DsbA-mediated disulfide bond formation incapacitates diverse β-lactamases and destabilizes mobile colistin resistance enzymes. Furthermore, we show that chemical inhibition of DsbA sensitizes multidrug-resistant clinical isolates to existing antibiotics and that the absence of DsbA, in combination with antibiotic treatment, substantially increases the survival of Galleria mellonella larvae infected with multidrug-resistant Pseudomonas aeruginosa. This work lays the foundation for the development of novel antibiotic adjuvants that function as broad-acting resistance breakers.},
   author = {R. Christopher D. Furniss and Nikol Kadeřábková and Declan Barker and Patricia Bernal and Evgenia Maslova and Amanda A.A. Antwi and Helen E. McNeil and Hannah L. Pugh and Laurent Dortet and Jessica M.A. Blair and Gerald Larrouy-Maumus and Ronan R. McCarthy and Diego Gonzalez and Despoina A.I. Mavridou},
   doi = {10.7554/eLife.57974},
   issn = {2050084X},
   journal = {eLife},
   month = {1},
   pmid = {35025730},
   publisher = {eLife Sciences Publications Ltd},
   title = {Breaking antimicrobial resistance by disrupting extracytoplasmic protein folding},
   volume = {11},
   year = {2022},
}
@article{Yang2018,
   abstract = {Motivation: Machine-learning models trained on protein sequences and their measured functions can infer biological properties of unseen sequences without requiring an understanding of the underlying physical or biological mechanisms. Such models enable the prediction and discovery of sequences with optimal properties. Machine-learning models generally require that their inputs be vectors, and the conversion from a protein sequence to a vector representation affects the model's ability to learn. We propose to learn embedded representations of protein sequences that take advantage of the vast quantity of unmeasured protein sequence data available. These embeddings are low-dimensional and can greatly simplify downstream modeling. Results: The predictive power of Gaussian process models trained using embeddings is comparable to those trained on existing representations, which suggests that embeddings enable accurate predictions despite having orders of magnitude fewer dimensions. Moreover, embeddings are simpler to obtain because they do not require alignments, structural data, or selection of informative amino-Acid properties. Visualizing the embedding vectors shows meaningful relationships between the embedded proteins are captured.},
   author = {Kevin K. Yang and Zachary Wu and Claire N. Bedbrook and Frances H. Arnold},
   doi = {10.1093/bioinformatics/bty178},
   issn = {14602059},
   issue = {15},
   journal = {Bioinformatics},
   month = {8},
   pages = {2642-2648},
   pmid = {29584811},
   publisher = {Oxford University Press},
   title = {Learned protein embeddings for machine learning},
   volume = {34},
   year = {2018},
}
@misc{Streicher2021,
   abstract = {Antibiotic resistance is projected to be one of the greatest healthcare challenges of the 21st century. As the efficacy of these critical drugs wanes and the discovery of new antibiotics stagnates, exploration of alternative therapies could offer a much needed solution. Although numerous alternative therapies are currently under investigation, three in particular appear poised for long-term success, namely antimicrobial oligonucleotides, monoclonal antibodies and phage therapy. Antimicrobial oligonucleotides could conceivably offer the greatest spectrum of activity while having the lowest chance of unrecoverable resistance. Bacteriophages, while most susceptible to resistance, are inexhaustible, inexpensive and exceptionally adept at eliminating biofilm-associated infections. And although monoclonal antibodies may have limited access to such recalcitrant bacteria, these agents are uniquely able to neutralise exotoxins and other diffusible virulence factors. This comparative review seeks to illuminate these promising therapies and to encourage the scientific and financial support necessary to usher in the next generation of infectious disease treatment.},
   author = {Laura Michelle Streicher},
   doi = {10.1016/j.jgar.2020.12.025},
   issn = {22137173},
   journal = {Journal of Global Antimicrobial Resistance},
   keywords = {Antibiotic alternative,Antibiotic resistance,Antisense oligonucleotide,Monoclonal antibody,Phage therapy,Short interfering RNA},
   month = {3},
   pages = {285-295},
   pmid = {33484895},
   publisher = {Elsevier Ltd},
   title = {Exploring the future of infectious disease treatment in a post-antibiotic era: A comparative review of alternative therapeutics},
   volume = {24},
   year = {2021},
}
@article{Maffei2021,
   abstract = {Bacteriophages, the viruses infecting bacteria, hold great potential for the treatment of multidrug- resistant bacterial infections and other applications due to their unparalleled diversity and recent breakthroughs in their genetic engineering. However, fundamental knowledge of the molecular mechanisms underlying phage-host interactions is mostly confined to a few traditional model systems and did not keep pace with the recent massive expansion of the field. The true potential of molecular biology encoded by these viruses has therefore remained largely untapped, and phages for therapy or other applications are often still selected empirically. We therefore sought to promote a systematic exploration of phage- host interactions by composing a well-assorted library of 68 newly isolated phages infecting the model organism Escherichia coli that we share with the community as the BASEL (BActeriophage SElection for your Laboratory) collection. This collection is largely representative of natural E. coli phage diversity and was intensively characterized phenotypically and genomically alongside 10 well-studied traditional model phages. We experimentally determined essential host receptors of all phages, quantified their sensitivity to 11 defense systems across different layers of bacterial immunity, and matched these results to the phages' host range across a panel of pathogenic enterobacterial strains. Clear patterns in the distribution of phage phenotypes and genomic features highlighted systematic differences in the potency of different immunity systems and suggested the molecular basis of receptor specificity in several phage groups. Our results also indicate strong trade-offs between fitness traits like broad host recognition and resistance to bacterial immunity that might drive the divergent adaptation of different phage groups to specific ecological niches. We envision that the BASEL collection will inspire future work exploring the biology of bacteriophages and their hosts by facilitating the discovery of underlying molecular mechanisms as the basis for an effective translation into biotechnology or therapeutic applications. Copyright:},
   author = {Enea Maffei and Aisylu Shaidullina and Marco Burkolter and Yannik Heyer and Fabienne Estermann and Valentin Druelle and Patrick Sauer and Luc Willi and Sarah Michaelis and Hubert Hilbi and David S. Thaler and Alexander Harms},
   doi = {10.1371/journal.pbio.3001424},
   issn = {15457885},
   issue = {11},
   journal = {PLoS Biology},
   month = {11},
   pmid = {34784345},
   publisher = {Public Library of Science},
   title = {Systematic exploration of Escherichia coli phage-host interactions with the BASEL phage collection},
   volume = {19},
   year = {2021},
}
@article{Villarroel2016,
   abstract = {The current dramatic increase of antibiotic resistant bacteria has revitalised the interest in bacteriophages as alternative antibacterial treatment. Meanwhile, the development of bioinformatics methods for analysing genomic data places high-throughput approaches for phage characterization within reach. Here, we present HostPhinder, a tool aimed at predicting the bacterial host of phages by examining the phage genome sequence. Using a reference database of 2196 phages with known hosts, HostPhinder predicts the host species of a query phage as the host of the most genomically similar reference phages. As a measure of genomic similarity the number of co-occurring k-mers (DNA sequences of length k) is used. Using an independent evaluation set, HostPhinder was able to correctly predict host genus and species for 81% and 74% of the phages respectively, giving predictions for more phages than BLAST and significantly outperforming BLAST on phages for which both had predictions. HostPhinder predictions on phage draft genomes from the INTESTI phage cocktail corresponded well with the advertised targets of the cocktail. Our study indicates that for most phages genomic similarity correlates well with related bacterial hosts. HostPhinder is available as an interactive web service [1] and as a stand alone download from the Docker registry [2].},
   author = {Julia Villarroel and Kortine Annina Kleinheinz and Vanessa Isabell Jurtz and Henrike Zschach and Ole Lund and Morten Nielsen and Mette Voldby Larsen},
   doi = {10.3390/v8050116},
   issn = {19994915},
   issue = {5},
   journal = {Viruses},
   keywords = {Genome,Host specificity,K-mers,Prediction},
   month = {5},
   pmid = {27153081},
   publisher = {MDPI AG},
   title = {HostPhinder: A phage host prediction tool},
   volume = {8},
   year = {2016},
}
@article{Li2021,
   abstract = {Multi-drug resistance (MDR) has become one of the greatest threats to human health worldwide, and novel treatment methods of infections caused by MDR bacteria are urgently needed. Phage therapy is a promising alternative to solve this problem, to which the key is correctly matching target pathogenic bacteria with the corresponding therapeutic phage. Deep learning is powerful for mining complex patterns to generate accurate predictions. In this study, we develop PredPHI (Predicting Phage-Host Interactions), a deep learning-based tool capable of predicting the host of phages from sequence data. We collect >3000 phage-host pairs along with their protein sequences from PhagesDB and GenBank databases and extract a set of features. Then we select high-quality negative samples based on the K-Means clustering method and construct a balanced training set. Finally, we employ a deep convolutional neural network to build the predictive model. The results indicate that PredPHI can achieve a predictive performance of 81 percent in terms of the area under the receiver operating characteristic curve on the test set, and the clustering-based method is significantly more robust than that based on randomly selecting negative samples. These results highlight that PredPHI is a useful and accurate tool for identifying phage-host interactions from sequence data.},
   author = {Menglu Li and Yanan Wang and Fuyi Li and Yun Zhao and Mengya Liu and Sijia Zhang and Yannan Bin and A. Ian Smith and Geoffrey I. Webb and Jian Li and Jiangning Song and Junfeng Xia},
   doi = {10.1109/TCBB.2020.3017386},
   issn = {15579964},
   issue = {5},
   journal = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
   keywords = {Phage-host interaction,bioinformatics,deep learning,multi-drug resistance,pattern recognition,sequence analysis},
   pages = {1801-1810},
   pmid = {32813660},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {A Deep Learning-Based Method for Identification of Bacteriophage-Host Interaction},
   volume = {18},
   year = {2021},
}
@article{Edwards2016,
   abstract = {Metagenomics has changed the face of virus discovery by enabling the accurate identification of viral genome sequences without requiring isolation of the viruses. As a result, metagenomic virus discovery leaves the first and most fundamental question about any novel virus unanswered: What host does the virus infect? The diversity of the global virosphere and the volumes of data obtained in metagenomic sequencing projects demand computational tools for virus-host prediction. We focus on bacteriophages (phages, viruses that infect bacteria), the most abundant and diverse group of viruses found in environmental metagenomes. By analyzing 820 phages with annotated hosts, we review and assess the predictive power of in silico phage-host signals. Sequence homology approaches are the most effective at identifying known phage-host pairs. Compositional and abundance-based methods contain significant signal for phage-host classification, providing opportunities for analyzing the unknowns in viral metagenomes. Together, these computational approaches further our knowledge of the interactions between phages and their hosts. Importantly, we find that all reviewed signals significantly link phages to their hosts, illustrating how current knowledge and insights about the interaction mechanisms and ecology of coevolving phages and bacteria can be exploited to predict phage-host relationships, with potential relevance for medical and industrial applications.},
   author = {Robert A. Edwards and Katelyn McNair and Karoline Faust and Jeroen Raes and Bas E. Dutilh},
   doi = {10.1093/femsre/fuv048},
   issn = {15746976},
   issue = {2},
   journal = {FEMS Microbiology Reviews},
   keywords = {CRISPR,Co-occurrence,Metagenomics,Oligonucleotide usage,Phages,Viruses of microbes},
   month = {1},
   pages = {258-272},
   pmid = {26657537},
   publisher = {Oxford University Press},
   title = {Computational approaches to predict bacteriophage-host relationships},
   volume = {40},
   year = {2016},
}
@article{Giacomelli2020,
   abstract = {Italy was the first European country hit by the COVID-19 pandemic and has the highest number of recorded COVID-19 deaths in Europe. This prospective cohort study of the correlates of the risk of death in COVID-19 patients was conducted at the Infectious Diseases and Intensive Care units of Luigi Sacco Hospital, Milan, Italy. The clinical characteristics of all the COVID-19 patients hospitalised in the early days of the epidemic (21 February -19 March 2020) were recorded upon admission, and the time-dependent probability of death was evaluated using the Kaplan-Meier method (censored as of 20 April 2020). Cox proportional hazard models were used to assess the factors independently associated with the risk of death. Forty-eight (20.6 %) of the 233 patients followed up for a median of 40 days (interquartile range 33–47) died during the follow-up. Most were males (69.1 %) and their median age was 61 years (IQR 50–72). The time-dependent probability of death was 19.7 % (95 % CI 14.6–24.9 %) 30 days after hospital admission. Age (adjusted hazard ratio [aHR] 2.08, 95 % CI 1.48−2.92 per ten years more) and obesity (aHR 3.04, 95 % CI 1.42−6.49) were independently associated with an increased risk of death, which was also associated with critical disease (aHR 8.26, 95 % CI 1.41−48.29), C-reactive protein levels (aHR 1.17, 95 % CI 1.02−1.35 per 50 mg/L more) and creatinine kinase levels above 185 U/L (aHR 2.58, 95 % CI 1.37−4.87) upon admission. Case-fatality rate of patients hospitalized with COVID-19 in the early days of the Italian epidemic was about 20 %. Our study adds evidence to the notion that older age, obesity and more advanced illness are factors associated to an increased risk of death among patients hospitalized with COVID-19.},
   author = {Andrea Giacomelli and Anna Lisa Ridolfo and Laura Milazzo and Letizia Oreni and Dario Bernacchia and Matteo Siano and Cecilia Bonazzetti and Alice Covizzi and Marco Schiuma and Matteo Passerini and Marco Piscaglia and Massimo Coen and Guido Gubertini and Giuliano Rizzardini and Chiara Cogliati and Anna Maria Brambilla and Riccardo Colombo and Antonio Castelli and Roberto Rech and Agostino Riva and Alessandro Torre and Luca Meroni and Stefano Rusconi and Spinello Antinori and Massimo Galli},
   doi = {10.1016/j.phrs.2020.104931},
   issn = {10961186},
   journal = {Pharmacological Research},
   keywords = {30-day mortality,Advanced age,Italy,Obesity,SARS-CoV-2},
   month = {8},
   pmid = {32446978},
   publisher = {Academic Press},
   title = {30-day mortality in patients hospitalized with COVID-19 during the first wave of the Italian epidemic: A prospective cohort study},
   volume = {158},
   year = {2020},
}
@article{Mohr2016,
   abstract = {For thousands of years people were delivered helplessly to various kinds of infections, which often reached epidemic proportions and have cost the lives of millions of people. This is precisely the age since mankind has been thinking of infectious diseases and the question of their causes. However, due to a lack of knowledge, the search for strategies to fight, heal, and prevent the spread of communicable diseases was unsuccessful for a long time. It was not until the discovery of the healing effects of (antibiotic producing) molds, the first microscopic observations of microorganisms in the seventeenth century, the refutation of the abiogenesis theory, and the dissolution of the question “What is the nature of infectious diseases?” that the first milestones within the history of antibiotics research were set. Then new discoveries accelerated rapidly: Bacteria could be isolated and cultured and were identified as possible agents of diseases as well as producers of bioactive metabolites. At the same time the first synthetic antibiotics were developed and shortly thereafter, thousands of synthetic substances as well as millions of soil borne bacteria and fungi were screened for bioactivity within numerous microbial laboratories of pharmaceutical companies. New antibiotic classes with different targets were discovered as on assembly line production. With the beginning of the twentieth century, many of the diseases which reached epidemic proportions at the time-e.g., cholera, syphilis, plague, tuberculosis, or typhoid fever, just to name a few, could be combatted with new discovered antibiotics. It should be considered that hundred years ago the market launch of new antibiotics was significantly faster and less complicated than today (where it takes 10-12 years in average between the discovery of a new antibiotic until the launch). After the first euphoria it was quickly realized that bacteria are able to develop, acquire, and spread numerous resistance mechanisms. Whenever a new antibiotic reached the market it did not take long until scientists observed the first resistant germs. Since the marketing of the first antibiotic there is a neck-on-neck race between scientists who discover natural or develop semisynthetic and synthetic bioactive molecules and bacteria, which have developed resistance mechanisms. The emphasis of this chapter is to give an overview of the history of antibiotics research. The situation within the pre-antibiotic era as well as in the early antibiotic era will be described until the Golden Age of Antibiotics will conclude this time travel. The most important antibiotic classes, information about their discovery, activity spectrum, mode of action, resistance mechanisms, and current application will be presented.},
   author = {Kathrin I. Mohr},
   doi = {10.1007/82_2016_499},
   issn = {21969965},
   journal = {Current Topics in Microbiology and Immunology},
   month = {12},
   pages = {237-272},
   pmid = {27738915},
   publisher = {Springer Verlag},
   title = {History of antibiotics research},
   volume = {398},
   year = {2016},
}
@article{Hesslow2022,
   abstract = {In this work we introduce RITA: a suite of autoregressive generative models for protein sequences, with up to 1.2 billion parameters, trained on over 280 million protein sequences belonging to the UniRef-100 database. Such generative models hold the promise of greatly accelerating protein design. We conduct the first systematic study of how capabilities evolve with model size for autoregressive transformers in the protein domain: we evaluate RITA models in next amino acid prediction, zero-shot fitness, and enzyme function prediction, showing benefits from increased scale. We release the RITA models openly, to the benefit of the research community.},
   author = {Daniel Hesslow and Niccoló Zanichelli and Pascal Notin and Iacopo Poli and Debora Marks},
   month = {5},
   title = {RITA: a Study on Scaling Up Generative Protein Sequence Models},
   url = {http://arxiv.org/abs/2205.05789},
   year = {2022},
}
@article{Tang2021,
   abstract = {Proteins are the basic substances that undertake human life activities, and they often perform their biological functions through interactions with other biological macromolecules, such as cell transmission and signal transduction. Predicting the interaction sites between proteins can deepen the understanding of the principle of protein interactions, but traditional experimental methods are time-consuming and labor-intensive. In this study, a new hierarchical attention network structure, named HANPPIS, by adding six effective features of protein sequence, position-specific scoring matrix (PSSM), secondary structure, pre-training vector, hydrophilic, and amino acid position, is proposed to predict protein–protein interaction (PPI) sites. The experiment proved that our model has obtained very effective results, which was better than the existing advanced calculation methods. More importantly, we used the double-layer attention mechanism to improve the interpretability of the model and to a certain extent solved the problem of the “black box” of deep neural networks, which can be used as a reference for location positioning on the biological level.},
   author = {Minli Tang and Longxin Wu and Xinyu Yu and Zhaoqi Chu and Shuting Jin and Juan Liu},
   doi = {10.3389/fgene.2021.784863},
   issn = {16648021},
   journal = {Frontiers in Genetics},
   keywords = {deep learning,feature fusion,multilevel attention mechanism,protein features,protein–protein interaction},
   month = {11},
   publisher = {Frontiers Media S.A.},
   title = {Prediction of Protein–Protein Interaction Sites Based on Stratified Attentional Mechanisms},
   volume = {12},
   year = {2021},
}
@article{Boeckaerts2022,
   abstract = {Receptor-binding proteins (RBPs) of bacteriophages initiate the infection of their corre-sponding bacterial host and act as the primary determinant for host specificity. The ever-increasing amount of sequence data enables the development of predictive models for the automated identification of RBP sequences. However, the development of such models is challenged by the incon-sistent or missing annotation of many phage proteins. Recently developed tools have started to bridge this gap but are not specifically focused on RBP sequences, for which many different anno-tations are available. We have developed two parallel approaches to alleviate the complex identification of RBP sequences in phage genomic data. The first combines known RBP-related hidden Markov models (HMMs) from the Pfam database with custom-built HMMs to identify phage RBPs based on protein domains. The second approach consists of training an extreme gradient boosting classifier that can accurately discriminate between RBPs and other phage proteins. We explained how these complementary approaches can reinforce each other in identifying RBP sequences. In addition, we benchmarked our methods against the recently developed PhANNs tool. Our best performing model reached a precision-recall area-under-the-curve of 93.8% and outperformed PhANNs on an independent test set, reaching an F1-score of 84.0% compared to 69.8%.},
   author = {Dimitri Boeckaerts and Michiel Stock and Bernard De Baets and Yves Briers},
   doi = {10.3390/v14061329},
   issn = {19994915},
   issue = {6},
   journal = {Viruses},
   keywords = {extreme gradient boosting,hidden Markov models,machine learning,phage,receptor-binding protein},
   month = {6},
   publisher = {MDPI},
   title = {Identification of Phage Receptor-Binding Protein Sequences with Hidden Markov Models and an Extreme Gradient Boosting Classifier},
   volume = {14},
   year = {2022},
}
@article{Yeung2023,
   abstract = {Protein language models, trained on millions of biologically observed sequences, generate feature-rich numerical representations of protein sequences. These representations, called sequence embeddings, can infer structure-functional properties, despite protein language models being trained on primary sequence alone. While sequence embeddings have been applied toward tasks such as structure and function prediction, applications toward alignment-free sequence classification have been hindered by the lack of studies to derive, quantify and evaluate relationships between protein sequence embeddings. Here, we develop workflows and visualization methods for the classification of protein families using sequence embedding derived from protein language models. A benchmark of manifold visualization methods reveals that Neighbor Joining (NJ) embedding trees are highly effective in capturing global structure while achieving similar performance in capturing local structure compared with popular dimensionality reduction techniques such as t-SNE and UMAP. The statistical significance of hierarchical clusters on a tree is evaluated by resampling embeddings using a variational autoencoder (VAE). We demonstrate the application of our methods in the classification of two well-studied enzyme superfamilies, phosphatases and protein kinases. Our embedding-based classifications remain consistent with and extend upon previously published sequence alignment-based classifications. We also propose a new hierarchical classification for the S-Adenosyl-L-Methionine (SAM) enzyme superfamily which has been difficult to classify using traditional alignment-based approaches. Beyond applications in sequence classification, our results further suggest NJ trees are a promising general method for visualizing high-dimensional data sets.},
   author = {Wayland Yeung and Zhongliang Zhou and Liju Mathew and Nathan Gravel and Rahil Taujale and Brady O'Boyle and Mariah Salcedo and Aarya Venkat and William Lanzilotta and Sheng Li and Natarajan Kannan},
   doi = {10.1093/bib/bbac619},
   issn = {14774054},
   issue = {1},
   journal = {Briefings in Bioinformatics},
   keywords = {deep learning,hierarchical clustering,manifold visualization,protein language models,representation learning,sequence classification},
   month = {1},
   pmid = {36642409},
   publisher = {Oxford University Press},
   title = {Tree visualizations of protein sequence embedding space enable improved functional clustering of diverse protein superfamilies},
   volume = {24},
   year = {2023},
}
@article{Brandes2022,
   abstract = {Summary: Self-supervised deep language modeling has shown unprecedented success across natural language tasks, and has recently been repurposed to biological sequences. However, existing models and pretraining methods are designed and optimized for text analysis. We introduce ProteinBERT, a deep language model specifically designed for proteins. Our pretraining scheme combines language modeling with a novel task of Gene Ontology (GO) annotation prediction. We introduce novel architectural elements that make the model highly efficient and flexible to long sequences. The architecture of ProteinBERT consists of both local and global representations, allowing end-to-end processing of these types of inputs and outputs. ProteinBERT obtains near state-of-the-art performance, and sometimes exceeds it, on multiple benchmarks covering diverse protein properties (including protein structure, post-translational modifications and biophysical attributes), despite using a far smaller and faster model than competing deep-learning methods. Overall, ProteinBERT provides an efficient framework for rapidly training protein predictors, even with limited labeled data.},
   author = {Nadav Brandes and Dan Ofer and Yam Peleg and Nadav Rappoport and Michal Linial},
   doi = {10.1093/bioinformatics/btac020},
   issn = {14602059},
   issue = {8},
   journal = {Bioinformatics},
   month = {4},
   pages = {2102-2110},
   pmid = {35020807},
   publisher = {Oxford University Press},
   title = {ProteinBERT: a universal deep-learning model of protein sequence and function},
   volume = {38},
   year = {2022},
}
@article{Zhou2022,
   abstract = {Phage–microbe interactions are appealing systems to study coevolution, and have also been increasingly emphasized due to their roles in human health, disease, and the development of novel therapeutics. Phage–microbe interactions leave diverse signals in bacterial and phage genomic sequences, defined as phage–host interaction signals (PHISs), which include clustered regularly interspaced short palindromic repeats (CRISPR) targeting, prophage, and protein–protein interaction signals. In the present study, we developed a novel tool phage–host interaction signal detector (PHISDetector) to predict phage–host interactions by detecting and integrating diverse in silico PHISs, and scoring the probability of phage–host interactions using machine learning models based on PHIS features. We evaluated the performance of PHISDetector on multiple benchmark datasets and application cases. When tested on a dataset of 758 annotated phage–host pairs, PHISDetector yields the prediction accuracies of 0.51 and 0.73 at the species and genus levels, respectively, outperforming other phage–host prediction tools. When applied to on 125,842 metagenomic viral contigs (mVCs) derived from 3042 geographically diverse samples, a detection rate of 54.54% could be achieved. Furthermore, PHISDetector could predict infecting phages for 85.6% of 368 multidrug-resistant (MDR) bacteria and 30% of 454 human gut bacteria obtained from the National Institutes of Health (NIH) Human Microbiome Project (HMP). The PHISDetector can be run either as a web server (http://www.microbiome-bigdata.com/PHISDetector/) for general users to study individual inputs or as a stand-alone version (https://github.com/HIT-ImmunologyLab/PHISDetector) to process massive phage contigs from virome studies.},
   author = {Fengxia Zhou and Rui Gan and Fan Zhang and Chunyan Ren and Ling Yu and Yu Si and Zhiwei Huang},
   doi = {10.1016/j.gpb.2022.02.003},
   issn = {22103244},
   issue = {3},
   journal = {Genomics, Proteomics and Bioinformatics},
   keywords = {CRISPR,Machine learning,Phage–host interaction,Prophage,Virome},
   month = {6},
   pages = {508-523},
   pmid = {35272051},
   publisher = {Beijing Genomics Institute},
   title = {PHISDetector: A Tool to Detect Diverse In Silico Phage–host Interaction Signals for Virome Studies},
   volume = {20},
   year = {2022},
}
@article{,
   abstract = {Membrane efflux pumps play a major role in bacterial multidrug resistance. The tripartite multidrug efflux pump system from Escherichia coli, AcrAB-TolC, is a target for inhibition to lessen resistance development and restore antibiotic efficacy, with homologs in other ESKAPE pathogens. Here, we rationalize a mechanism of inhibition against the periplasmic adaptor protein, AcrA, using a combination of hydrogen/deuterium exchange mass spectrometry, cellular efflux assays, and molecular dynamics simulations. We define the structural dynamics of AcrA and find that an inhibitor can inflict long-range stabilisation across all four of its domains, whereas an interacting efflux substrate has minimal effect. Our results support a model where an inhibitor forms a molecular wedge within a cleft between the lipoyl and αβ barrel domains of AcrA, diminishing its conformational transmission of drug-evoked signals from AcrB to TolC. This work provides molecular insights into multidrug adaptor protein function which could be valuable for developing antimicrobial therapeutics.},
   author = {Benjamin Russell Lewis and Muhammad R. Uddin and Mohammad Moniruzzaman and Katie M. Kuo and Anna J. Higgins and Laila M.N. Shah and Frank Sobott and Jerry M. Parks and Dietmar Hammerschmid and James C. Gumbart and Helen I. Zgurskaya and Eamonn Reading},
   doi = {10.1038/s41467-023-39615-x},
   issn = {20411723},
   issue = {1},
   journal = {Nature Communications},
   month = {12},
   pmid = {37463890},
   publisher = {Nature Research},
   title = {Conformational restriction shapes the inhibition of a multidrug efflux adaptor protein},
   volume = {14},
   year = {2023},
}
@article{,
   abstract = {Variant effect predictors (VEPs) provide a potential solution to the influx of variants of uncertain clinical significance produced by genome sequencing studies. However, the assessment of VEP performance is fraught with biases introduced by benchmarking against clinical observations. In this study, building on our previous work, we use independently generated measurements of protein function from deep mutational scanning (DMS) experiments for 26 human proteins to benchmark 55 different VEPs, while introducing minimum data circularity. The top VEPs are dominated by unsupervised methods including EVE, DeepSequence and ESM-1v, a new protein language model that ranked first overall. However, the strong performance of recent supervised VEPs, in particular VARITY, shows that developers are taking data circularity and bias issues seriously. We also assess the performance of DMS and unsupervised VEPs for discriminating between known pathogenic and putatively benign missense variants. Our findings are mixed, demonstrating that some DMS datasets perform exceptionally at variant classification, while others are poor. Notably, we observe a striking correlation between VEP agreement with DMS data and performance in identifying clinically relevant variants, with EVE, DeepSequence and ESM-1v performing best, further supporting the utility of DMS as an independent benchmark.},
   author = {Benjamin J Livesey and Joseph A Marsh},
   doi = {10.1101/2022.11.19.517196},
   title = {Updated benchmarking of variant effect predictors using deep mutational scanning},
   url = {https://doi.org/10.1101/2022.11.19.517196},
}
@article{Hatfull2022,
   abstract = {Antibiotic resistance in bacterial pathogens presents a substantial threat to the control of infectious diseases. Development of new classes of antibiotics has slowed in recent years due to pressures of cost and market profitability, and there is a strong need for new antimicrobial therapies. The therapeutic use of bacteriophages has long been considered, with numerous anecdotal reports of success. Interest in phage therapy has been renewed by recent clinical successes in case studies with personalized phage cocktails, and several clinical trials are in progress. We discuss recent progress in the therapeutic use of phages and contemplate the key factors influencing the opportunities and challenges. With strong safety profiles, the main challenges of phage therapeutics involve strain variation among clinical isolates of many pathogens, battling phage resistance, and the potential limitations of host immune responses. However, the opportunities are considerable, with the potential to enhance current antibiotic efficacy, protect newly developed antibiotics , and provide a last resort in response to complete antibiotic failure.},
   author = {Graham F Hatfull and Rebekah M Dedrick and Robert T Schooley},
   doi = {10.1146/annurev-med-080219},
   journal = {Annu. Rev. Med. 2022},
   keywords = {antimicrobial resistance,bacteriophages,phage therapy},
   pages = {197-211},
   title = {Downloaded from www.annualreviews.org Access provided by 185.107.13.14 on 01/11/24. For personal use only},
   volume = {73},
   url = {https://doi.org/10.1146/annurev-med-080219-},
   year = {2022},
}
@misc{,
   author = {Joseph Lister},
   title = {S.8THE BRITISH MEDICAL JOURZVAL. REMARKS MICRO-ORGANISMS: THEIR RELATION TO DISEASE.*},
}
@misc{Larsson2022,
   abstract = {Antibiotic resistance is a global health challenge, involving the transfer of bacteria and genes between humans, animals and the environment. Although multiple barriers restrict the flow of both bacteria and genes, pathogens recurrently acquire new resistance factors from other species, thereby reducing our ability to prevent and treat bacterial infections. Evolutionary events that lead to the emergence of new resistance factors in pathogens are rare and challenging to predict, but may be associated with vast ramifications. Transmission events of already widespread resistant strains are, on the other hand, common, quantifiable and more predictable, but the consequences of each event are limited. Quantifying the pathways and identifying the drivers of and bottlenecks for environmental evolution and transmission of antibiotic resistance are key components to understand and manage the resistance crisis as a whole. In this Review, we present our current understanding of the roles of the environment, including antibiotic pollution, in resistance evolution, in transmission and as a mere reflection of the regional antibiotic resistance situation in the clinic. We provide a perspective on current evidence, describe risk scenarios, discuss methods for surveillance and the assessment of potential drivers, and finally identify some actions to mitigate risks.},
   author = {D. G.Joakim Larsson and Carl Fredrik Flach},
   doi = {10.1038/s41579-021-00649-x},
   issn = {17401534},
   issue = {5},
   journal = {Nature Reviews Microbiology},
   month = {5},
   pages = {257-269},
   pmid = {34737424},
   publisher = {Nature Research},
   title = {Antibiotic resistance in the environment},
   volume = {20},
   year = {2022},
}
@misc{,
   abstract = {The major epidemic and pandemic diseases that have bothered humans since the Neolithic Age and Bronze Age are surveyed. Many of these pandemics are zoonotic infections, and the mathematical modeling of such infections is illustrated. Plague, cholera, syphilis, influenza, SARS, MERS, COVID-19, and new potential epidemic and pandemic infections and their consequences are described and the background for the spread of acute and chronic infections and the transition to endemic infections is discussed. The way we can prevent and fight pandemics is illustrated from the old and new well-known pandemics. Surprisingly, the political reactions through different periods have not changed much during the centuries.},
   author = {Niels Høiby},
   doi = {10.1111/apm.13098},
   issn = {16000463},
   issue = {7},
   journal = {APMIS},
   keywords = {COVID-19,MERS,Pandemics,SARS,cholera,epidemics,influenza,plague},
   month = {7},
   pages = {352-371},
   pmid = {33244837},
   publisher = {John Wiley and Sons Inc},
   title = {Pandemics: past, present, future: That is like choosing between cholera and plague},
   volume = {129},
   year = {2021},
}
@article{Bateman2023,
   abstract = {The aim of the UniProt Knowledgebase is to provide users with a comprehensive, high-quality and freely accessible set of protein sequences annotated with functional information. In this publication we describe enhancements made to our data processing pipeline and to our website to adapt to an ever-increasing information content. The number of sequences in UniProtKB has risen to over 227 million and we are working towards including a reference proteome for each taxonomic group. We continue to extract detailed annotations from the literature to update or create reviewed entries, while unreviewed entries are supplemented with annotations provided by automated systems using a variety of machine-learning techniques. In addition, the scientific community continues their contributions of publications and annotations to UniProt entries of their interest. Finally, we describe our new website (https://www.uniprot.org/), designed to enhance our users’ experience and make our data easily accessible to the research community. This interface includes access to AlphaFold structures for more than 85% of all entries as well as improved visualisations for subcellular localisation of proteins.},
   author = {Alex Bateman and Maria Jesus Martin and Sandra Orchard and Michele Magrane and Shadab Ahmad and Emanuele Alpi and Emily H. Bowler-Barnett and Ramona Britto and Hema Bye-A-Jee and Austra Cukura and Paul Denny and Tunca Dogan and Thank God Ebenezer and Jun Fan and Penelope Garmiri and Leonardo Jose da Costa Gonzales and Emma Hatton-Ellis and Abdulrahman Hussein and Alexandr Ignatchenko and Giuseppe Insana and Rizwan Ishtiaq and Vishal Joshi and Dushyanth Jyothi and Swaathi Kandasaamy and Antonia Lock and Aurelien Luciani and Marija Lugaric and Jie Luo and Yvonne Lussi and Alistair MacDougall and Fabio Madeira and Mahdi Mahmoudy and Alok Mishra and Katie Moulang and Andrew Nightingale and Sangya Pundir and Guoying Qi and Shriya Raj and Pedro Raposo and Daniel L. Rice and Rabie Saidi and Rafael Santos and Elena Speretta and James Stephenson and Prabhat Totoo and Edward Turner and Nidhi Tyagi and Preethi Vasudev and Kate Warner and Xavier Watkins and Rossana Zaru and Hermann Zellner and Alan J. Bridge and Lucila Aimo and Ghislaine Argoud-Puy and Andrea H. Auchincloss and Kristian B. Axelsen and Parit Bansal and Delphine Baratin and Teresa M. Batista Neto and Marie Claude Blatter and Jerven T. Bolleman and Emmanuel Boutet and Lionel Breuza and Blanca Cabrera Gil and Cristina Casals-Casas and Kamal Chikh Echioukh and Elisabeth Coudert and Beatrice Cuche and Edouard de Castro and Anne Estreicher and Maria L. Famiglietti and Marc Feuermann and Elisabeth Gasteiger and Pascale Gaudet and Sebastien Gehant and Vivienne Gerritsen and Arnaud Gos and Nadine Gruaz and Chantal Hulo and Nevila Hyka-Nouspikel and Florence Jungo and Arnaud Kerhornou and Philippe Le Mercier and Damien Lieberherr and Patrick Masson and Anne Morgat and Venkatesh Muthukrishnan and Salvo Paesano and Ivo Pedruzzi and Sandrine Pilbout and Lucille Pourcel and Sylvain Poux and Monica Pozzato and Manuela Pruess and Nicole Redaschi and Catherine Rivoire and Christian J.A. Sigrist and Karin Sonesson and Shyamala Sundaram and Cathy H. Wu and Cecilia N. Arighi and Leslie Arminski and Chuming Chen and Yongxing Chen and Hongzhan Huang and Kati Laiho and Peter McGarvey and Darren A. Natale and Karen Ross and C. R. Vinayaka and Qinghua Wang and Yuqi Wang and Jian Zhang},
   doi = {10.1093/nar/gkac1052},
   issn = {13624962},
   issue = {D1},
   journal = {Nucleic Acids Research},
   month = {1},
   pages = {D523-D531},
   pmid = {36408920},
   publisher = {Oxford University Press},
   title = {UniProt: the Universal Protein Knowledgebase in 2023},
   volume = {51},
   year = {2023},
}
@article{Langer1964,
   author = {William L Langer},
   doi = {10.2307/24936021},
   issue = {2},
   pages = {114-121},
   title = {THE BLACK DEATH},
   volume = {210},
   year = {1964},
}
@article{,
   abstract = {of increase of antibiotic resistance and ambient temperature in Europe: a cross-national analysis of 28 countries between 2000 and 2016. Euro Surveill. 2020;25(45):pii=1900414. https://doi. Background: The rapid increase of bacterial antibiotic resistance could soon render our most effective method to address infections obsolete. Factors influencing pathogen resistance prevalence in human populations remain poorly described, though temperature is known to contribute to mechanisms of spread. Aim: To quantify the role of temperature, spatially and temporally , as a mechanistic modulator of transmission of antibiotic resistant microbes. Methods: An ecologic analysis was performed on country-level antibiotic resistance prevalence in three common bacterial pathogens across 28 European countries, collectively representing over 4 million tested isolates. Associations of minimum temperature and other predictors with change in antibiotic resistance rates over 17 years (2000-2016) were evaluated with multivariable models. The effects of predictors on the antibiotic resistance rate change across geographies were quantified. Results: During 2000-2016, for Escherichia coli and Klebsiella pneumoniae, European countries with 10°C warmer ambient minimum temperatures compared to others, experienced more rapid resistance increases across all antibiotic classes. Increases ranged between 0.33%/year (95% CI: 0.2 to 0.5) and 1.2%/year (95% CI: 0.4 to 1.9), even after accounting for recognised resistance drivers including antibiotic consumption and population density. For Staphylococcus aureus a decreasing relationship of −0.4%/year (95% CI: −0.7 to 0.0) was found for meticillin resistance , reflecting widespread declines in meticillin-resistant S. aureus across Europe over the study period. Conclusion: We found evidence of a long-term effect of ambient minimum temperature on antibiotic resistance rate increases in Europe. Ambient temperature might considerably influence antibiotic resistance growth rates, and explain geographic differences observed in cross-sectional studies. Rising temperatures globally may hasten resistance spread, complicating mitigation efforts.},
   author = {Sarah F McGough and Derek R MacFadden and Mohammad W Hattab and Kåre Mølbak and Mauricio Santillana and McGough F Sarah and MacFadden R Derek and Hattab W Mohammad and Mølbak Kåre and Santillana Mauricio Rates},
   doi = {10.2807/1560},
   pages = {1},
   title = {Rates of increase of antibiotic resistance and ambient temperature in Europe: a cross-national analysis of 28 countries between 2000 and 2016},
   url = {www.eurosurveillance.org},
}
@misc{,
   abstract = {The Synthetic Minority Oversampling Technique (SMOTE) preprocessing algorithm is considered "de facto" standard in the framework of learning from imbalanced data. This is due to its simplicity in the design of the procedure, as well as its robustness when applied to different type of problems. Since its publication in 2002, SMOTE has proven successful in a variety of applications from several different domains. SMOTE has also inspired several approaches to counter the issue of class imbalance, and has also significantly contributed to new supervised learning paradigms, including multilabel classification, in-cremental learning, semi-supervised learning, multi-instance learning, among others. It is standard benchmark for learning from imbalanced data. It is also featured in a number of different software packages-from open source to commercial. In this paper, marking the fifteen year anniversary of SMOTE, we reflect on the SMOTE journey, discuss the current state of affairs with SMOTE, its applications, and also identify the next set of challenges to extend SMOTE for Big Data problems.},
   author = {Alberto Fernández and Salvador García and Francisco Herrera and Nitesh V Chawla},
   journal = {Journal of Artificial Intelligence Research},
   pages = {863-905},
   title = {SMOTE for Learning from Imbalanced Data: Progress and Challenges, Marking the 15-year Anniversary},
   volume = {61},
   year = {2018},
}
@article{Livesey2023,
   abstract = {The assessment of variant effect predictor (VEP) performance is fraught with biases introduced by benchmarking against clinical observations. In this study, building on our previous work, we use independently generated measurements of protein function from deep mutational scanning (DMS) experiments for 26 human proteins to benchmark 55 different VEPs, while introducing minimal data circularity. Many top‐performing VEPs are unsupervised methods including EVE, DeepSequence and ESM‐1v, a protein language model that ranked first overall. However, the strong performance of recent supervised VEPs, in particular VARITY, shows that developers are taking data circularity and bias issues seriously. We also assess the performance of DMS and unsupervised VEPs for discriminating between known pathogenic and putatively benign missense variants. Our findings are mixed, demonstrating that some DMS datasets perform exceptionally at variant classification, while others are poor. Notably, we observe a striking correlation between VEP agreement with DMS data and performance in identifying clinically relevant variants, strongly supporting the validity of our rankings and the utility of DMS for independent benchmarking.   image    Common sources of bias in variant effect predictor benchmarking are assessed using data from deep mutational scanning experiments. ESM‐1v, EVE and DeepSequence are among the top performers on both functionally validated and clinically observed variants.   Deep mutational scanning datasets from 26 human proteins are used to benchmark 55 computational predictors of missense variant effect.   The top‐performing methods include several very recent predictors and are based mostly on unsupervised machine learning methodologies.   There is a strong correlation between predictor performance when benchmarked against deep mutational scanning data and clinical variants.   },
   author = {Benjamin J Livesey and Joseph A Marsh},
   doi = {10.15252/msb.202211474},
   issn = {1744-4292},
   issue = {8},
   journal = {Molecular Systems Biology},
   month = {8},
   pmid = {37310135},
   publisher = {Springer Science and Business Media LLC},
   title = {Updated benchmarking of variant effect predictors using deep mutational scanning},
   volume = {19},
   year = {2023},
}
@article{Nijkamp2022,
   abstract = {Attention-based models trained on protein sequences have demonstrated incredible success at classification and generation tasks relevant for artificial intelligence-driven protein design. However, we lack a sufficient understanding of how very large-scale models and data play a role in effective protein model development. We introduce a suite of protein language models, named ProGen2, that are scaled up to 6.4B parameters and trained on different sequence datasets drawn from over a billion proteins from genomic, metagenomic, and immune repertoire databases. ProGen2 models show state-of-the-art performance in capturing the distribution of observed evolutionary sequences, generating novel viable sequences, and predicting protein fitness without additional finetuning. As large model sizes and raw numbers of protein sequences continue to become more widely accessible, our results suggest that a growing emphasis needs to be placed on the data distribution provided to a protein sequence model. We release the ProGen2 models and code at https://github.com/salesforce/progen.},
   author = {Erik Nijkamp and Jeffrey Ruffolo and Eli N. Weinstein and Nikhil Naik and Ali Madani},
   month = {6},
   title = {ProGen2: Exploring the Boundaries of Protein Language Models},
   url = {http://arxiv.org/abs/2206.13517},
   year = {2022},
}
@article{Madani2020,
   abstract = {Generative modeling for protein engineering is key to solving fundamental problems in synthetic biology, medicine, and material science. We pose protein engineering as an unsupervised sequence generation problem in order to leverage the exponentially growing set of proteins that lack costly, structural annotations. We train a 1.2B-parameter language model, ProGen, on ∼280M protein sequences conditioned on taxonomic and keyword tags such as molecular function and cellular component. This provides ProGen with an unprecedented range of evolutionary sequence diversity and allows it to generate with fine-grained control as demonstrated by metrics based on primary sequence similarity, secondary structure accuracy, and conformational energy.},
   author = {Ali Madani and Bryan Mccann and Nikhil Naik and Nitish Shirish Keskar and Namrata Anand and Raphael R Eguchi and Po-Ssu Huang and Richard Socher},
   doi = {10.1101/2020.03.07.982272},
   keywords = {conditional,controllable,generative,language modeling,protein,sequences},
   title = {ProGen: Language Modeling for Protein Generation},
   url = {https://doi.org/10.1101/2020.03.07.982272},
   year = {2020},
}
@article{,
   abstract = {In the field of artificial intelligence, a combination of scale in data and model capacity enabled by unsupervised learning has led to major advances in representation learning and statistical generation. In the life sciences, the anticipated growth of sequencing promises unprecedented data on natural sequence diversity. Protein language modeling at the scale of evolution is a logical step toward predictive and generative artificial intelligence for biology. To this end, we use unsupervised learning to train a deep contextual language model on 86 billion amino acids across 250 million protein sequences spanning evolutionary diversity. The resulting model contains information about biological properties in its representations. The representations are learned from sequence data alone. The learned representation space has a multiscale organization reflecting structure from the level of biochemical properties of amino acids to remote homology of proteins. Information about secondary and tertiary structure is encoded in the representations and can be identified by linear projections. Representation learning produces features that generalize across a range of applications, enabling state-of-the-art supervised prediction of mutational effect and secondary structure and improving state-of-the-art features for long-range contact prediction. generative biology | representation learning | protein language model | deep learning | synthetic biology G rowth in the number of protein sequences in public databases has followed an exponential trend over decades, creating a deep view into the breadth and diversity of protein sequences across life. These data are a promising ground for studying pre-dictive and generative models for biology using artificial intelligence. Our focus here will be to fit a single model to many diverse sequences from across evolution. Accordingly we study high-capacity neural networks, investigating what can be learned about the biology of proteins from modeling evolutionary data at scale. The idea that biological function and structure are recorded in the statistics of protein sequences selected through evolution has a long history (1-3). Out of the possible random perturbations to a sequence, evolution is biased toward selecting those that are consistent with fitness (4). The unobserved variables that determine a protein's fitness, such as structure, function, and stability , leave a record in the distribution of observed natural sequences (4). Unlocking the information encoded in protein sequence variation is a longstanding problem in biology. An analogous problem in the field of artificial intelligence is natural language understanding, where the distributional hypothesis posits that a word's semantics can be derived from the contexts in which it appears (5). Recently, techniques based on self-supervision, a form of un-supervised learning in which context within the text is used to predict missing words, have been shown to materialize representations of word meaning that can generalize across natural language tasks (6-9). The ability to learn such representations improves significantly with larger training datasets (10, 11). Protein sequences result from a process greatly dissimilar to natural language. It is uncertain whether the models and objective functions effective for natural language transfer across differences between the domains. We explore this question by training high-capacity Transformer language models on evolutionary data. We investigate the resulting unsupervised representations for the presence of biological organizing principles and information about intrinsic biological properties. We find metric structure in the representation space that accords with organizing principles at scales from physicochemical to remote homology. We also find that secondary and tertiary protein structure can be identified in representations. The structural properties captured by the representations generalize across folds. We apply the representations to a range of prediction tasks and find that they improve state-of-art features across the applications. Background Sequence alignment and search is a standard basis for comparative and statistical analysis of biological sequence data (12-15).},
   author = {Alexander Rives and Joshua Meier and Tom Sercu and Siddharth Goyal and Zeming Lin and Jason Liu and Demi Guo and Myle Ott and C Lawrence Zitnick and Jerry Ma and Rob Fergus},
   doi = {10.1073/pnas.2016239118/-/DCSupplemental},
   title = {Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences},
   url = {https://www.pnas.org},
}
@article{Pahil2024,
   abstract = {<p> Gram-negative bacteria are extraordinarily difficult to kill because their cytoplasmic membrane is surrounded by an outer membrane that blocks the entry of most antibiotics. The impenetrable nature of the outer membrane is due to the presence of a large, amphipathic glycolipid called lipopolysaccharide (LPS) in its outer leaflet <sup>1</sup> . Assembly of the outer membrane requires transport of LPS across a protein bridge that spans from the cytoplasmic membrane to the cell surface. Maintaining outer membrane integrity is essential for bacterial cell viability, and its disruption can increase susceptibility to other antibiotics <sup>2–6</sup> . Thus, inhibitors of the seven lipopolysaccharide transport (Lpt) proteins that form this transenvelope transporter have long been sought. A new class of antibiotics that targets the LPS transport machine in <italic>Acinetobacter</italic> was recently identified. Here, using structural, biochemical and genetic approaches, we show that these antibiotics trap a substrate-bound conformation of the LPS transporter that stalls this machine. The inhibitors accomplish this by recognizing a composite binding site made up of both the Lpt transporter and its LPS substrate. Collectively, our findings identify an unusual mechanism of lipid transport inhibition, reveal a druggable conformation of the Lpt transporter and provide the foundation for extending this class of antibiotics to other Gram-negative pathogens. </p>},
   author = {Karanbir S. Pahil and Morgan S. A. Gilman and Vadim Baidin and Thomas Clairfeuille and Patrizio Mattei and Christoph Bieniossek and Fabian Dey and Dieter Muri and Remo Baettig and Michael Lobritz and Kenneth Bradley and Andrew C. Kruse and Daniel Kahne},
   doi = {10.1038/s41586-023-06799-7},
   issn = {0028-0836},
   issue = {7995},
   journal = {Nature},
   month = {1},
   pages = {572-577},
   title = {A new antibiotic traps lipopolysaccharide in its intermembrane transporter},
   volume = {625},
   url = {https://www.nature.com/articles/s41586-023-06799-7},
   year = {2024},
}
@article{,
   abstract = {Proteins usually perform their cellular functions by interacting with other proteins. Accurate identification of protein-protein interaction sites (PPIs) from sequence is import for designing new drugs and developing novel therapeutics. A lot of computational models for PPIs prediction have been developed because experimental methods are slow and expensive. Most models employ a sliding window approach in which local neighbors are concatenated to present a target residue. However, those neighbors are not been distinguished by pairwise information between a neighbor and the target. In this study, we propose a novel PPIs prediction model AttCNNPPISP, which combines attention mechanism and convolutional neural networks (CNNs). The attention mechanism dynamically captures the pairwise correlation of each neighbor-target pair within a sliding window, and therefore makes a better understanding of the local environment of target residue. And then, CNNs take the local representation as input to make prediction. Experiments are employed on several public benchmark datasets. Compared with the state-of-the-art models, AttCNNPPISP significantly improves the prediction performance. Also, the experimental results demonstrate that the attention mechanism is effective in terms of constructing comprehensive context information of target residue.},
   author = {Shuai Lu and Yuguang Li and Qiang Ma and Xiaofei Nan and Shoutao Zhang},
   doi = {10.1101/2021.07.10.451856},
   keywords = {CNNs,Index Terms-PPIs prediction,attention mechanism,sequenced-based},
   title = {Protein-Protein Interaction Site Prediction Based on Attention Mechanism and Convolutional Neural Networks},
   url = {https://doi.org/10.1101/2021.07.10.451856},
}
@misc{Wang2021,
   abstract = {Escherichia coli is generally used as model bacteria to define microbial cell factories for many products and to investigate regulation mechanisms. E. coli exhibits phospholipids, lipopolysaccharides, colanic acid, flagella and type I fimbriae on the outer membrane which is a self-protective barrier and closely related to cellular morphology, growth, phenotypes and stress adaptation. However, these outer membrane associated molecules could also lead to potential contamination and insecurity for fermentation products and consume lots of nutrients and energy sources. Therefore, understanding critical insights of these membrane associated molecules is necessary for building better microbial producers. Here the biosynthesis, function, influences, and current membrane engineering applications of these outer membrane associated molecules were reviewed from the perspective of synthetic biology, and the potential and effective engineering strategies on the outer membrane to improve fermentation features for microbial cell factories were suggested.},
   author = {Jianli Wang and Wenjian Ma and Xiaoyuan Wang},
   doi = {10.1186/s12934-021-01565-8},
   issn = {14752859},
   issue = {1},
   journal = {Microbial Cell Factories},
   keywords = {Escherichia coli,Exopolysaccharide,Fimbria,Flagella,Inclusion bodies,Lipopolysaccharide,Membrane engineering,Microbial cell factories,Outer membrane,Poly-3-hydroxybutyrate},
   month = {12},
   pmid = {33743682},
   publisher = {BioMed Central Ltd},
   title = {Insights into the structure of Escherichia coli outer membrane as the target for engineering microbial cell factories},
   volume = {20},
   year = {2021},
}
@article{Naqvi2021,
   abstract = {Since the emergence of yellow fever in the Americas and the devastating 1918 influenza pandemic, biologists and clinicians have been drawn to human infecting viruses to understand their mechanisms of infection better and develop effective therapeutics against them. However, the complex molecular and cellular processes that these viruses use to infect and multiply in human cells have been a source of great concern for the scientific community since the discovery of the first human infecting virus. Viral disease outbreaks, such as the recent COVID-19 pandemic caused by a novel coronavirus, have claimed millions of lives and caused significant economic damage worldwide. In this study, we investigated the mechanisms of host-virus interaction and the molecular machinery involved in the pathogenesis of some common human viruses. We also performed a phylogenetic analysis of viral proteins involved in host-virus interaction to understand the changes in the sequence organization of these proteins during evolution for various strains of viruses to gain insights into the viral origin’s evolutionary perspectives.},
   author = {Ahmad Abu Turab Naqvi and Farah Anjum and Alaa Shafie and Sufian Badar and Abdelbaset Mohamed Elasbali and Dharmendra Kumar Yadav and Md Imtaiyaz Hassan},
   doi = {10.1371/journal.pone.0261497},
   issn = {19326203},
   issue = {12 December},
   journal = {PLoS ONE},
   month = {12},
   pmid = {34914801},
   publisher = {Public Library of Science},
   title = {Investigating host-virus interaction mechanism and phylogenetic analysis of viral proteins involved in the pathogenesis},
   volume = {16},
   year = {2021},
}
@article{Roux2023,
   abstract = {The extraordinary diversity of viruses infecting bacteria and archaea is now primarily studied through metagenomics. While metagenomes enable high-throughput exploration of the viral sequence space, metagenome-derived sequences lack key information compared to isolated viruses, in particular host association. Different computational approaches are available to predict the host(s) of uncultivated viruses based on their genome sequences, but thus far individual approaches are limited either in precision or in recall, i.e., for a number of viruses they yield erroneous predictions or no prediction at all. Here, we describe iPHoP, a two-step framework that integrates multiple methods to reliably predict host taxonomy at the genus rank for a broad range of viruses infecting bacteria and archaea, while retaining a low false discovery rate. Based on a large dataset of metagenome-derived virus genomes from the IMG/VR database, we illustrate how iPHoP can provide extensive host prediction and guide further characterization of uncultivated viruses.},
   author = {Simon Roux and Antonio Pedro Camargo and Felipe H. Coutinho and Shareef M. Dabdoub and Bas E. Dutilh and Stephen Nayfach and Andrew Tritt},
   doi = {10.1371/journal.pbio.3002083},
   issn = {15457885},
   issue = {4},
   journal = {PLoS Biology},
   month = {4},
   pmid = {37083735},
   publisher = {Public Library of Science},
   title = {iPHoP: An integrated machine learning framework to maximize host prediction for metagenome-derived viruses of archaea and bacteria},
   volume = {21},
   year = {2023},
}
